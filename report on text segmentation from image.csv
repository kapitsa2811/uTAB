
#######################################################################################
1. Initially encoder-decoder-train_4.py is created to segment words from images. (Results2_for_publication_1.tar.gz gDrive)

2. It consumes input images and segment images.

3.Input images are created from a)generateFiles.py b)generateFiles_1.py

4. a) creates line level annotation. b) creates word level annotation.

5. a) and b) are present in project dataGenerationImage.

6. Results of this code is communicated with Nene madam and backup is present on onedrive paperPublication/textSegmentationResults 


#######################################################################################
encoder-decoder-train_5.py  (slidingWindowExperiment gDrive)

1) This code is part of experiment using sliding window on training data and testing data.

2)For it initial images are generated by a)generateFiles.py b)generateFiles_1.py which is present at /home/kapitsa/pyCharm/dataGenerationImage

3) These images are then passed to sliding window module which extracts non overlaping windows of training and text data.

4) For sliding window code used is MyOCRService callSlidingWindow.py --> slidingWindow_1.py (slidingWindow.py not in use)

#######################################################################################

newArchitectureExperiment : this experiment uses architecture from already published papers.

Code for it is present in encoder-decoder-train_6.py at   at  location /home/kapitsa/pyCharm/segmentation/Convolutional-Encoder-Decoder-for-Hand-Segmentation-master
